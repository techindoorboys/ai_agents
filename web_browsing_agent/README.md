# ğŸŒ Web Browsing AI Agent (Gemini-powered)

A production-ready **Web Browsing AI Agent** that fetches live web pages and generates concise summaries using **Google Gemini LLM**.  
The system is built with **FastAPI, LangGraph, Streamlit, and uv**, and is designed to run seamlessly in **GitHub Codespaces**.

---

## ğŸš€ Features

- ğŸ” Fetches real web pages using `requests` + `BeautifulSoup`
- ğŸ§  Summarizes content using **Gemini 1.5 Flash**
- ğŸ§© Agent orchestration using **LangGraph**
- âš¡ FastAPI backend with clean API contracts
- ğŸ¨ Simple Streamlit UI
- ğŸ” Secure environment variable management using `.env`
- ğŸ§‘â€ğŸ’» Optimized for **GitHub Codespaces**
- ğŸ—ï¸ Clean, extensible architecture (easy to add search, crawl, QA)

---

## ğŸ—ï¸ Architecture Overview
```
User
  â”‚
  â–¼
Streamlit UI
  â”‚
  â–¼
FastAPI Backend
  â”‚
  â–¼
LangGraph Agent
  â”œâ”€â”€ Fetch Web Page
  â””â”€â”€ Summarize Content
  â”‚
  â–¼
Gemini 1.5 Flash
```
---
## ğŸ“‚ Project Structure
```
web_browsing_agent/
â”œâ”€â”€ backend/
â”‚ â”œâ”€â”€ app/
â”‚ â”‚ â”œâ”€â”€ agent/
â”‚ â”‚ â”‚ â”œâ”€â”€ graph.py # LangGraph workflow
â”‚ â”‚ â”‚ â”œâ”€â”€ tools.py # Web fetching logic
â”‚ â”‚ â”‚ â””â”€â”€ llm.py # Gemini client
â”‚ â”‚ â”œâ”€â”€ api.py # FastAPI routes
â”‚ â”‚ â”œâ”€â”€ schemas.py # Pydantic models
â”‚ â”‚ â””â”€â”€ main.py # App entry point
â”‚ â””â”€â”€ pyproject.toml
â”‚
â”œâ”€â”€ frontend/
â”‚ â”œâ”€â”€ app.py # Streamlit UI
â”‚ â””â”€â”€ pyproject.toml
â”‚
â”œâ”€â”€ .env # Environment variables
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```
---
## ğŸ› ï¸ Tech Stack

| Layer | Technology |
|-----|-----------|
| Language | Python 3.11+ |
| Backend | FastAPI |
| Frontend | Streamlit |
| Agent Framework | LangGraph |
| LLM | Google Gemini 1.5 Flash |
| Package Manager | `uv` |
| Web Parsing | BeautifulSoup |
| Environment Mgmt | python-dotenv |
| Deployment | GitHub Codespaces |

---

## ğŸ”‘ Environment Variables

Create a `.env` file at the **project root**:

```env
GOOGLE_API_KEY=your_gemini_api_key_here
BACKEND_URL=http://localhost:8000
âš ï¸ Do NOT commit .env to GitHub
Add it to .gitignore.

â–¶ï¸ Running the Project (GitHub Codespaces)
1ï¸âƒ£ Install uv (once)
```
pip install uv
```
2ï¸âƒ£ Backend Setup (FastAPI)
```
cd backend
uv venv
source .venv/bin/activate
uv pip install -r pyproject.toml
uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload
```
âœ… API Docs:
http://localhost:8000/docs

3ï¸âƒ£ Frontend Setup (Streamlit)
Open a new terminal:
```
cd frontend
uv venv
source .venv/bin/activate
uv pip install -r pyproject.toml
streamlit run app.py --server.port 8501 --server.address 0.0.0.0
```
âœ… UI will open automatically via Codespaces port forwarding.

ğŸ§ª Test URLs
Use these to verify the app:

arduino
Copy code
https://en.wikipedia.org/wiki/Artificial_intelligence
https://en.wikipedia.org/wiki/Machine_learning
ğŸ§  How the Agent Works
User enters a URL in Streamlit

FastAPI receives the request

LangGraph executes:

Node 1: Fetch webpage content

Node 2: Summarize using Gemini

Summary returned to UI

âš ï¸ Common Issues & Fixes
403 Forbidden Error
âœ” Fixed by sending browser-like User-Agent headers

Gemini Model Not Found
âœ” Use new SDK (google-genai)
âœ” Use Gemini 1.5 models

API Key Not Loaded
âœ” Avoid accessing env vars at import time
âœ” Load .env before LLM usage

ğŸ”’ Security Best Practices
API keys loaded at runtime (not import time)

.env excluded from version control

LLM initialized lazily

No secrets in frontend

ğŸ§© Extending the Project
This project is intentionally modular. You can easily add:

ğŸ” Web search tool

ğŸ“š Multi-page crawling

ğŸ§  Question answering over pages

âœ‚ï¸ Chunking for long documents

ğŸ“‘ Structured summaries (bullets, headings)

ğŸ”„ Streaming LLM responses

âš¡ Async execution

ğŸ¯ Who Is This For?
AI / ML Engineers

Backend Engineers

Product Engineers working with LLMs

Interview & portfolio projects

Anyone learning Agentic AI systems

ğŸ“œ License
MIT License â€“ feel free to use, modify, and build upon it.

â­ If you like this project
Give it a â­ on GitHub and feel free to fork or contribute!